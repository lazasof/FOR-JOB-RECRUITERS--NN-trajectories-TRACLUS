{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Model\n"
      ],
      "metadata": {
        "id": "WEvoLvAu1vTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_pickle('/content/drive/MyDrive/t10df_20210719.pkl')\n",
        "\n",
        "#dfall = pd.read_csv('/content/drive/MyDrive/dfdist66037minlns4573.csv',index_col=0)\n",
        "#grouped=dfall.groupby(dfall['clusterId'])\n",
        "#df_0 = grouped.get_group(0).copy()\n",
        "#df_1 = grouped.get_group(1).copy()\n",
        "#df_2 = grouped.get_group(2).copy()\n",
        "#tags_of_0=df_0['tags'].unique()\n",
        "#tags_of_1=df_1['tags'].unique()\n",
        "#tags_of_2=df_2['tags'].unique()\n",
        "data\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import glob\n",
        "import shutil\n",
        "import pickle\n",
        "import os\n",
        "import time\n",
        "from pandas import concat\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "#pip install -U scikit-learn scipy matplotlib\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data['column_mmsi'] = np.where(data[\"mmsi(t-1)\"] == data[\"mmsi(t)\"], True, False)\n",
        "false_count = (~data.column_mmsi).sum()\n",
        "true_count = (data.column_mmsi).sum()\n",
        "print(\"num of false mmsi\",(false_count))\n",
        "print(\"num of true mmsi\",(true_count))\n",
        "\n",
        "data['column_id'] = np.where(data[\"id(t-1)\"] == data[\"id(t)\"], True, False)\n",
        "false_count_id = (~data.column_id).sum()\n",
        "true_count_id = (data.column_id).sum()\n",
        "print(\"num of false id\",(false_count_id))\n",
        "print(\"num of true id\",(true_count_id))\n",
        "\n",
        "#to id dinei to trip (mporw na xrhsimopoihsw ws timegap 1 h)\n",
        "\n",
        "data = data[data['column_mmsi'] == True] #drop rows where column id is false, id(t)=/=id(t-1)\n",
        "data['column_mmsi'] = np.where(data[\"mmsi(t-1)\"] == data[\"mmsi(t)\"], True, False)\n",
        "false_count = (~data.column_mmsi).sum()\n",
        "true_count = (data.column_mmsi).sum()\n",
        "print(\"num of false mmsi\",(false_count))\n",
        "print(\"num of true mmsi\",(true_count))\n",
        "\n",
        "data['column_id'] = np.where(data[\"id(t-1)\"] == data[\"id(t)\"], True, False)\n",
        "false_count_id = (~data.column_id).sum()\n",
        "true_count_id = (data.column_id).sum()\n",
        "print(\"num of false id\",(false_count_id))\n",
        "print(\"num of true id\",(true_count_id))\n",
        "print(\"now mmsi(t) == mmsi(t-1) \")\n",
        "#shift me group, short me xrono\n",
        "\n",
        "df0=data.copy()\n",
        "df0 = df0[df0.columns.drop(list(df0.filter(regex='mmsi')))]\n",
        "df0 = df0[df0.columns.drop(list(df0.filter(regex='dataset_tr1_val2_test3_augm_0_norm')))]\n",
        "df0 = df0[df0.columns.drop(list(df0.filter(regex='id')))]\n",
        "df0 = df0[df0.columns.drop(list(df0.filter(regex='WGS84')))]\n",
        "df0 = df0[df0.columns.drop(list(df0.filter(regex='dist_m')))]\n",
        "\n",
        "\n",
        "df0=df0.drop(labels=['t(t-10)', 't(t-9)','t(t-8)','t(t-7)',\n",
        "                 't(t-6)','t(t-5)','t(t-4)', 't(t-3)','t(t-2)','t(t-1)','t(t)','dt(t-10)'], axis=1) \n",
        "\n",
        "df0=df0.drop(labels=['dataset_tr1_val2_test3_augm_0(t-9)', 'dataset_tr1_val2_test3_augm_0(t-8)',\n",
        "                     'dataset_tr1_val2_test3_augm_0(t-7)','dataset_tr1_val2_test3_augm_0(t-6)',\n",
        "                 'dataset_tr1_val2_test3_augm_0(t-5)','dataset_tr1_val2_test3_augm_0(t-4)',\n",
        "                     'dataset_tr1_val2_test3_augm_0(t-3)', 'dataset_tr1_val2_test3_augm_0(t-2)',\n",
        "                     'dataset_tr1_val2_test3_augm_0(t-1)','dataset_tr1_val2_test3_augm_0(t)'], axis=1) \n",
        "\n",
        "\n",
        "grouped=df0.groupby(df0['dataset_tr1_val2_test3_augm_0(t-10)'])\n",
        "#training data shenanigans\n",
        "df_tr = grouped.get_group(1.0)\n",
        "df_tr1=df_tr.copy()\n",
        "#to thelw gia to telos\n",
        "dftrainzlon=df_tr1[[\"lon(t-1)\"]]\n",
        "dftrainzlat=df_tr1[[\"lat(t-1)\"]]\n",
        "#drop lon lats\n",
        "df_trx=df_tr.filter(regex=(\"^dlon|^dlat*|^speed|^dt\"))\n",
        "df_trx=df_trx.drop(labels=['dlon(t)', 'dlat(t)'], axis=1)\n",
        "df_try=df_tr1[[\"dlon(t)\",\"dlat(t)\"]]\n",
        "\n",
        "#validation data shenanigans\n",
        "df_val= grouped.get_group(2.0)\n",
        "df_val1=df_val.copy()\n",
        "#to thelw just in case\n",
        "dfvalzlon=df_val1[[\"lon(t-1)\"]]\n",
        "dfvalzlat=df_val1[[\"lat(t-1)\"]]\n",
        "#drop lon lats\n",
        "df_valx=df_val.filter(regex=(\"^dlon|^dlat*|^speed|^dt\"))\n",
        "df_valx=df_valx.drop(labels=['dlon(t)', 'dlat(t)'], axis=1)\n",
        "df_valy=df_val1[[\"dlon(t)\",\"dlat(t)\"]]\n",
        "\n",
        "#testing data shenanigans\n",
        "df_test = grouped.get_group(3.0)\n",
        "df_test1=df_test.copy()\n",
        "#to thelw gia to telos\n",
        "#edw eixa kanei to lathos na balw dftestzlon=df_VAL1[[\"lon(t-1)\"]] \n",
        "dftestzlon=df_test1[[\"lon(t-1)\"]]\n",
        "dftestzlat=df_test1[[\"lat(t-1)\"]]\n",
        "#drop lon lats\n",
        "df_testx=df_test.filter(regex=(\"^dlon|^dlat*|^speed|^dt\"))\n",
        "df_testx=df_testx.drop(labels=['dlon(t)', 'dlat(t)'], axis=1)\n",
        "df_testy =df_test1[[\"dlon(t)\",\"dlat(t)\"]]\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "scaler1 = StandardScaler()#StandardScaler(),MinMaxScaler(feature_range=(0, 1))\n",
        "scaler2 = StandardScaler()\n",
        "scaler3 = StandardScaler()\n",
        "scaler4 = StandardScaler()\n",
        "scaler5 = StandardScaler()\n",
        "scaler6 = StandardScaler()\n",
        "\n",
        "\n",
        "columns=['dlon(t-10)','dlat(t-10)','speed(t-10)','dlon(t-9)','dlat(t-9)','dt(t-9)','speed(t-9)','dlon(t-8)','dlat(t-8)','dt(t-8)',\n",
        "         'speed(t-8)','dlon(t-7)','dlat(t-7)','dt(t-7)','speed(t-7)','dlon(t-6)','dlat(t-6)','dt(t-6)','speed(t-6)','dlon(t-5)','dlat(t-5)',\n",
        "         'dt(t-5)','speed(t-5)','dlon(t-4)','dlat(t-4)','dt(t-4)','speed(t-4)','dlon(t-3)','dlat(t-3)','dt(t-3)','speed(t-3)','dlon(t-2)',\n",
        "         'dlat(t-2)','dt(t-2)','speed(t-2)','dlon(t-1)','dlat(t-1)','dt(t-1)','speed(t-1)','dt(t)','speed(t)']\n",
        "\n",
        "df_trx[columns]=scaler1.fit_transform(df_trx[columns])\n",
        "df_try[['dlon(t)','dlat(t)']]=scaler2.fit_transform(df_try[['dlon(t)','dlat(t)']])\n",
        "df_valx[columns]=scaler3.fit_transform(df_valx[columns])\n",
        "df_valy[['dlon(t)','dlat(t)']]=scaler4.fit_transform(df_valy[['dlon(t)','dlat(t)']])\n",
        "df_testx[columns]=scaler5.fit_transform(df_testx[columns])\n",
        "df_testy[['dlon(t)','dlat(t)']]=scaler6.fit_transform(df_testy[['dlon(t)','dlat(t)']])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5sMVBsHtJQY",
        "outputId": "03e9fcc9-fe64-41f8-9c8e-c0d382d04580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num of false mmsi 0\n",
            "num of true mmsi 57616\n",
            "num of false id 0\n",
            "num of true id 57616\n",
            "num of false mmsi 0\n",
            "num of true mmsi 57616\n",
            "num of false id 0\n",
            "num of true id 57616\n",
            "now mmsi(t) == mmsi(t-1) \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "layer1='relu'\n",
        "    # Building a model with SimpleRNN \n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from tensorflow.keras.layers import (BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense)\n",
        "#lets try Dropout BatchNormalization shuflle  relu elu esu \n",
        "#define model and model parameters\n",
        "batch_size = 32\n",
        "model = Sequential()\n",
        "n_cols=df_trx.shape[1]\n",
        "n_rows=df_trx.shape[0]\n",
        "epochs=1000\n",
        "patience=10\n",
        "\n",
        "model.add(Dense(units=32, input_shape=(n_cols, ), activation=layer1))#relu,selu,sigmoid,tanh\n",
        "model.add(Dense(16, activation=layer1))\n",
        "model.add(Dense(8, activation=layer1))\n",
        "model.add(Dense(4, activation=layer1))\n",
        "model.add(Dense(2, activation=layer1))\n",
        "\n",
        "#compile model\n",
        "model.compile(loss='mae', optimizer='adam',metrics=['mean_absolute_error']) \n",
        "\n",
        "#fit model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpointer = ModelCheckpoint(filepath='weights.hdf5', save_best_only=True, \n",
        "                               save_weights_only=True, monitor='val_mean_absolute_error', mode='min', verbose=1)\n",
        "\n",
        "early_stopping_monitor = EarlyStopping(patience=patience)\n",
        "history=model.fit(df_trx, df_try, validation_data=(df_valx,df_valy), epochs=epochs, \n",
        "                  callbacks=[early_stopping_monitor,checkpointer], batch_size=batch_size, verbose=1,shuffle=True)\n",
        "model.summary()\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "#metrics to use accuracy, means_squared_error\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRXaaSRM151b",
        "outputId": "b81651ac-1d62-4443-c4ac-9e36da131ccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "804/811 [============================>.] - ETA: 0s - loss: 0.5175 - mean_absolute_error: 0.5175\n",
            "Epoch 1: val_mean_absolute_error improved from inf to 0.55072, saving model to weights.hdf5\n",
            "811/811 [==============================] - 5s 4ms/step - loss: 0.5173 - mean_absolute_error: 0.5173 - val_loss: 0.5507 - val_mean_absolute_error: 0.5507\n",
            "Epoch 2/1000\n",
            "790/811 [============================>.] - ETA: 0s - loss: 0.4643 - mean_absolute_error: 0.4643\n",
            "Epoch 2: val_mean_absolute_error improved from 0.55072 to 0.52530, saving model to weights.hdf5\n",
            "811/811 [==============================] - 3s 3ms/step - loss: 0.4637 - mean_absolute_error: 0.4637 - val_loss: 0.5253 - val_mean_absolute_error: 0.5253\n",
            "Epoch 3/1000\n",
            "810/811 [============================>.] - ETA: 0s - loss: 0.4516 - mean_absolute_error: 0.4516\n",
            "Epoch 3: val_mean_absolute_error improved from 0.52530 to 0.51883, saving model to weights.hdf5\n",
            "811/811 [==============================] - 2s 3ms/step - loss: 0.4516 - mean_absolute_error: 0.4516 - val_loss: 0.5188 - val_mean_absolute_error: 0.5188\n",
            "Epoch 4/1000\n",
            "794/811 [============================>.] - ETA: 0s - loss: 0.4464 - mean_absolute_error: 0.4464\n",
            "Epoch 4: val_mean_absolute_error did not improve from 0.51883\n",
            "811/811 [==============================] - 3s 4ms/step - loss: 0.4457 - mean_absolute_error: 0.4457 - val_loss: 0.5200 - val_mean_absolute_error: 0.5200\n",
            "Epoch 5/1000\n",
            "810/811 [============================>.] - ETA: 0s - loss: 0.4422 - mean_absolute_error: 0.4422\n",
            "Epoch 5: val_mean_absolute_error improved from 0.51883 to 0.51563, saving model to weights.hdf5\n",
            "811/811 [==============================] - 3s 4ms/step - loss: 0.4422 - mean_absolute_error: 0.4422 - val_loss: 0.5156 - val_mean_absolute_error: 0.5156\n",
            "Epoch 6/1000\n",
            "789/811 [============================>.] - ETA: 0s - loss: 0.4391 - mean_absolute_error: 0.4391\n",
            "Epoch 6: val_mean_absolute_error did not improve from 0.51563\n",
            "811/811 [==============================] - 2s 3ms/step - loss: 0.4392 - mean_absolute_error: 0.4392 - val_loss: 0.5156 - val_mean_absolute_error: 0.5156\n",
            "Epoch 7/1000\n",
            "796/811 [============================>.] - ETA: 0s - loss: 0.4372 - mean_absolute_error: 0.4372\n",
            "Epoch 7: val_mean_absolute_error improved from 0.51563 to 0.51023, saving model to weights.hdf5\n",
            "811/811 [==============================] - 2s 3ms/step - loss: 0.4372 - mean_absolute_error: 0.4372 - val_loss: 0.5102 - val_mean_absolute_error: 0.5102\n",
            "Epoch 8/1000\n",
            "784/811 [============================>.] - ETA: 0s - loss: 0.4354 - mean_absolute_error: 0.4354\n",
            "Epoch 8: val_mean_absolute_error did not improve from 0.51023\n",
            "811/811 [==============================] - 2s 3ms/step - loss: 0.4353 - mean_absolute_error: 0.4353 - val_loss: 0.5107 - val_mean_absolute_error: 0.5107\n",
            "Epoch 9/1000\n",
            "804/811 [============================>.] - ETA: 0s - loss: 0.4338 - mean_absolute_error: 0.4338\n",
            "Epoch 9: val_mean_absolute_error did not improve from 0.51023\n",
            "811/811 [==============================] - 2s 2ms/step - loss: 0.4336 - mean_absolute_error: 0.4336 - val_loss: 0.5112 - val_mean_absolute_error: 0.5112\n",
            "Epoch 10/1000\n",
            "807/811 [============================>.] - ETA: 0s - loss: 0.4323 - mean_absolute_error: 0.4323\n",
            "Epoch 10: val_mean_absolute_error did not improve from 0.51023\n",
            "811/811 [==============================] - 2s 3ms/step - loss: 0.4322 - mean_absolute_error: 0.4322 - val_loss: 0.5117 - val_mean_absolute_error: 0.5117\n",
            "Epoch 11/1000\n",
            "802/811 [============================>.] - ETA: 0s - loss: 0.4317 - mean_absolute_error: 0.4317\n",
            "Epoch 11: val_mean_absolute_error improved from 0.51023 to 0.50945, saving model to weights.hdf5\n",
            "811/811 [==============================] - 3s 3ms/step - loss: 0.4316 - mean_absolute_error: 0.4316 - val_loss: 0.5095 - val_mean_absolute_error: 0.5095\n",
            "Epoch 12/1000\n",
            "797/811 [============================>.] - ETA: 0s - loss: 0.4305 - mean_absolute_error: 0.4305\n",
            "Epoch 12: val_mean_absolute_error improved from 0.50945 to 0.50619, saving model to weights.hdf5\n",
            "811/811 [==============================] - 3s 4ms/step - loss: 0.4307 - mean_absolute_error: 0.4307 - val_loss: 0.5062 - val_mean_absolute_error: 0.5062\n",
            "Epoch 13/1000\n",
            "801/811 [============================>.] - ETA: 0s - loss: 0.4295 - mean_absolute_error: 0.4295\n",
            "Epoch 13: val_mean_absolute_error did not improve from 0.50619\n",
            "811/811 [==============================] - 2s 2ms/step - loss: 0.4295 - mean_absolute_error: 0.4295 - val_loss: 0.5070 - val_mean_absolute_error: 0.5070\n",
            "Epoch 14/1000\n",
            "802/811 [============================>.] - ETA: 0s - loss: 0.4293 - mean_absolute_error: 0.4293\n",
            "Epoch 14: val_mean_absolute_error did not improve from 0.50619\n",
            "811/811 [==============================] - 2s 2ms/step - loss: 0.4291 - mean_absolute_error: 0.4291 - val_loss: 0.5083 - val_mean_absolute_error: 0.5083\n",
            "Epoch 15/1000\n",
            "796/811 [============================>.] - ETA: 0s - loss: 0.4286 - mean_absolute_error: 0.4286\n",
            "Epoch 15: val_mean_absolute_error did not improve from 0.50619\n",
            "811/811 [==============================] - 2s 3ms/step - loss: 0.4287 - mean_absolute_error: 0.4287 - val_loss: 0.5105 - val_mean_absolute_error: 0.5105\n",
            "Epoch 16/1000\n",
            "810/811 [============================>.] - ETA: 0s - loss: 0.4277 - mean_absolute_error: 0.4277\n",
            "Epoch 16: val_mean_absolute_error improved from 0.50619 to 0.50591, saving model to weights.hdf5\n",
            "811/811 [==============================] - 2s 3ms/step - loss: 0.4277 - mean_absolute_error: 0.4277 - val_loss: 0.5059 - val_mean_absolute_error: 0.5059\n",
            "Epoch 17/1000\n",
            "801/811 [============================>.] - ETA: 0s - loss: 0.4268 - mean_absolute_error: 0.4268\n",
            "Epoch 17: val_mean_absolute_error did not improve from 0.50591\n",
            "811/811 [==============================] - 2s 3ms/step - loss: 0.4268 - mean_absolute_error: 0.4268 - val_loss: 0.5062 - val_mean_absolute_error: 0.5062\n",
            "Epoch 18/1000\n",
            "797/811 [============================>.] - ETA: 0s - loss: 0.4265 - mean_absolute_error: 0.4265\n",
            "Epoch 18: val_mean_absolute_error did not improve from 0.50591\n",
            "811/811 [==============================] - 3s 4ms/step - loss: 0.4264 - mean_absolute_error: 0.4264 - val_loss: 0.5077 - val_mean_absolute_error: 0.5077\n",
            "Epoch 19/1000\n",
            "804/811 [============================>.] - ETA: 0s - loss: 0.4254 - mean_absolute_error: 0.4254\n",
            "Epoch 19: val_mean_absolute_error did not improve from 0.50591\n",
            "811/811 [==============================] - 3s 4ms/step - loss: 0.4263 - mean_absolute_error: 0.4263 - val_loss: 0.5095 - val_mean_absolute_error: 0.5095\n",
            "Epoch 20/1000\n",
            "793/811 [============================>.] - ETA: 0s - loss: 0.4260 - mean_absolute_error: 0.4260\n",
            "Epoch 20: val_mean_absolute_error did not improve from 0.50591\n",
            "811/811 [==============================] - 2s 3ms/step - loss: 0.4257 - mean_absolute_error: 0.4257 - val_loss: 0.5080 - val_mean_absolute_error: 0.5080\n",
            "Epoch 21/1000\n",
            "795/811 [============================>.] - ETA: 0s - loss: 0.4253 - mean_absolute_error: 0.4253\n",
            "Epoch 21: val_mean_absolute_error did not improve from 0.50591\n",
            "811/811 [==============================] - 2s 2ms/step - loss: 0.4250 - mean_absolute_error: 0.4250 - val_loss: 0.5064 - val_mean_absolute_error: 0.5064\n",
            "Epoch 22/1000\n",
            "796/811 [============================>.] - ETA: 0s - loss: 0.4250 - mean_absolute_error: 0.4250\n",
            "Epoch 22: val_mean_absolute_error did not improve from 0.50591\n",
            "811/811 [==============================] - 2s 3ms/step - loss: 0.4251 - mean_absolute_error: 0.4251 - val_loss: 0.5088 - val_mean_absolute_error: 0.5088\n",
            "Epoch 23/1000\n",
            "799/811 [============================>.] - ETA: 0s - loss: 0.4253 - mean_absolute_error: 0.4253\n",
            "Epoch 23: val_mean_absolute_error improved from 0.50591 to 0.50578, saving model to weights.hdf5\n",
            "811/811 [==============================] - 2s 3ms/step - loss: 0.4251 - mean_absolute_error: 0.4251 - val_loss: 0.5058 - val_mean_absolute_error: 0.5058\n",
            "Epoch 24/1000\n",
            "805/811 [============================>.] - ETA: 0s - loss: 0.4248 - mean_absolute_error: 0.4248\n",
            "Epoch 24: val_mean_absolute_error improved from 0.50578 to 0.50181, saving model to weights.hdf5\n",
            "811/811 [==============================] - 4s 5ms/step - loss: 0.4246 - mean_absolute_error: 0.4246 - val_loss: 0.5018 - val_mean_absolute_error: 0.5018\n",
            "Epoch 25/1000\n",
            "809/811 [============================>.] - ETA: 0s - loss: 0.4241 - mean_absolute_error: 0.4241\n",
            "Epoch 25: val_mean_absolute_error did not improve from 0.50181\n",
            "811/811 [==============================] - 3s 4ms/step - loss: 0.4241 - mean_absolute_error: 0.4241 - val_loss: 0.5045 - val_mean_absolute_error: 0.5045\n",
            "Epoch 26/1000\n",
            "793/811 [============================>.] - ETA: 0s - loss: 0.4239 - mean_absolute_error: 0.4239\n",
            "Epoch 26: val_mean_absolute_error did not improve from 0.50181\n",
            "811/811 [==============================] - 2s 3ms/step - loss: 0.4237 - mean_absolute_error: 0.4237 - val_loss: 0.5118 - val_mean_absolute_error: 0.5118\n",
            "Epoch 27/1000\n",
            "809/811 [============================>.] - ETA: 0s - loss: 0.4237 - mean_absolute_error: 0.4237\n",
            "Epoch 27: val_mean_absolute_error did not improve from 0.50181\n",
            "811/811 [==============================] - 2s 3ms/step - loss: 0.4236 - mean_absolute_error: 0.4236 - val_loss: 0.5070 - val_mean_absolute_error: 0.5070\n",
            "Epoch 28/1000\n",
            "790/811 [============================>.] - ETA: 0s - loss: 0.4232 - mean_absolute_error: 0.4232\n",
            "Epoch 28: val_mean_absolute_error did not improve from 0.50181\n",
            "811/811 [==============================] - 2s 3ms/step - loss: 0.4230 - mean_absolute_error: 0.4230 - val_loss: 0.5045 - val_mean_absolute_error: 0.5045\n",
            "Epoch 29/1000\n",
            "805/811 [============================>.] - ETA: 0s - loss: 0.4228 - mean_absolute_error: 0.4228\n",
            "Epoch 29: val_mean_absolute_error did not improve from 0.50181\n",
            "811/811 [==============================] - 2s 3ms/step - loss: 0.4231 - mean_absolute_error: 0.4231 - val_loss: 0.5026 - val_mean_absolute_error: 0.5026\n",
            "Epoch 30/1000\n",
            "798/811 [============================>.] - ETA: 0s - loss: 0.4227 - mean_absolute_error: 0.4227\n",
            "Epoch 30: val_mean_absolute_error did not improve from 0.50181\n",
            "811/811 [==============================] - 2s 3ms/step - loss: 0.4229 - mean_absolute_error: 0.4229 - val_loss: 0.5021 - val_mean_absolute_error: 0.5021\n",
            "Epoch 31/1000\n",
            "810/811 [============================>.] - ETA: 0s - loss: 0.4225 - mean_absolute_error: 0.4225\n",
            "Epoch 31: val_mean_absolute_error did not improve from 0.50181\n",
            "811/811 [==============================] - 3s 4ms/step - loss: 0.4225 - mean_absolute_error: 0.4225 - val_loss: 0.5050 - val_mean_absolute_error: 0.5050\n",
            "Epoch 32/1000\n",
            "797/811 [============================>.] - ETA: 0s - loss: 0.4225 - mean_absolute_error: 0.4225\n",
            "Epoch 32: val_mean_absolute_error did not improve from 0.50181\n",
            "811/811 [==============================] - 4s 5ms/step - loss: 0.4225 - mean_absolute_error: 0.4225 - val_loss: 0.5035 - val_mean_absolute_error: 0.5035\n",
            "Epoch 33/1000\n",
            "792/811 [============================>.] - ETA: 0s - loss: 0.4220 - mean_absolute_error: 0.4220\n",
            "Epoch 33: val_mean_absolute_error did not improve from 0.50181\n",
            "811/811 [==============================] - 2s 2ms/step - loss: 0.4220 - mean_absolute_error: 0.4220 - val_loss: 0.5122 - val_mean_absolute_error: 0.5122\n",
            "Epoch 34/1000\n",
            "794/811 [============================>.] - ETA: 0s - loss: 0.4228 - mean_absolute_error: 0.4228\n",
            "Epoch 34: val_mean_absolute_error did not improve from 0.50181\n",
            "811/811 [==============================] - 2s 3ms/step - loss: 0.4221 - mean_absolute_error: 0.4221 - val_loss: 0.5055 - val_mean_absolute_error: 0.5055\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 32)                1344      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 4)                 36        \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 2)                 10        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,054\n",
            "Trainable params: 2,054\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "dict_keys(['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "\n",
        "# Predicting and plotting the result\n",
        "trainPredict = model.predict(df_trx, batch_size=batch_size)\n",
        "testPredict = model.predict(df_testx, batch_size=batch_size)\n",
        "\n",
        "# invert predictions\n",
        "#(25925, 1) (21585, 1)\n",
        "trainPredict = np.reshape(trainPredict, (-1, 2))\n",
        "ytr2d = np.reshape(df_try, (-1, 2))\n",
        "\n",
        "testPredict = np.reshape(testPredict, (-1, 2))\n",
        "yte2d = np.reshape(df_testy, (-1, 2))\n",
        "trainPredict\n",
        "\n",
        "\n",
        "trainPredict = scaler2.inverse_transform(trainPredict)\n",
        "trainY = scaler2.inverse_transform(ytr2d)\n",
        "\n",
        "testPredict = scaler6.inverse_transform(testPredict)\n",
        "testY = scaler6.inverse_transform(yte2d)\n",
        "\n",
        "dfpredict = pd.DataFrame(testPredict,columns=['dlon','dlat'])\n",
        "dftest= pd.DataFrame(testY,columns=['dlon','dlat'])\n",
        "trainPred= pd.DataFrame(trainPredict,columns=['dlon','dlat'])\n",
        "trainReal= pd.DataFrame(trainY,columns=['dlon','dlat'])\n",
        "\n",
        "\n",
        "\n",
        "dfpredictdlon= pd.DataFrame([])\n",
        "dftestdlon= pd.DataFrame([])\n",
        "trainPreddlon =pd.DataFrame([])\n",
        "trainRealdlon = pd.DataFrame([])\n",
        "dfpredictdlat= pd.DataFrame([])\n",
        "dftestdlat= pd.DataFrame([])\n",
        "trainPreddlat = pd.DataFrame([])\n",
        "trainRealdlat =pd.DataFrame([])\n",
        "\n",
        "dfpredictdlon['dlon']=dfpredict['dlon']\n",
        "dftestdlon['dlon']= dftest['dlon']\n",
        "trainPreddlon['dlon'] = trainPred['dlon']\n",
        "trainRealdlon['dlon'] = trainReal['dlon']\n",
        "dfpredictdlat['dlat']= dfpredict['dlat']\n",
        "dftestdlat['dlat']= dftest['dlat']\n",
        "trainPreddlat['dlat'] = trainPred['dlat']\n",
        "trainRealdlat['dlat'] = trainReal['dlat']\n",
        "\n",
        "\n",
        "dfpredictdlon['lon']=dftestzlon[\"lon(t-1)\"].values\n",
        "dfpredictdlat['lat'] =dftestzlat[\"lat(t-1)\"].values\n",
        "dftestdlon['lon']=dftestzlon[\"lon(t-1)\"].values\n",
        "dftestdlat['lat'] =dftestzlat[\"lat(t-1)\"].values\n",
        "\n",
        "trainPreddlon['lon'] =dftrainzlon[\"lon(t-1)\"].values\n",
        "trainRealdlon['lon'] =dftrainzlon[\"lon(t-1)\"].values\n",
        "trainPreddlat['lat'] =dftrainzlat[\"lat(t-1)\"].values\n",
        "trainRealdlat['lat'] =dftrainzlat[\"lat(t-1)\"].values\n",
        "\n",
        "\n",
        "\n",
        "#df.sum(axis = 1, skipna = True)\n",
        "\n",
        "trainPredlon= pd.DataFrame([])\n",
        "trainPredlat= pd.DataFrame([])\n",
        "trainReallon= pd.DataFrame([])\n",
        "trainReallat= pd.DataFrame([])\n",
        "dfpredictlon= pd.DataFrame([])\n",
        "dfpredictlat= pd.DataFrame([])\n",
        "dftestlon= pd.DataFrame([])\n",
        "dftestlat= pd.DataFrame([])\n",
        "dfpredictdlon['flon']=dfpredictdlon.sum(axis = 1, skipna = True)\n",
        "dfpredictdlat['flat']= dfpredictdlat.sum(axis = 1, skipna = True)\n",
        "dftestdlon['flon']= dftestdlon.sum(axis = 1, skipna = True)\n",
        "dftestdlat['flat']= dftestdlat.sum(axis = 1, skipna = True)\n",
        "\n",
        "trainPreddlon['flon']= trainPreddlon.sum(axis = 1, skipna = True)\n",
        "trainPreddlat['flat']= trainPreddlat.sum(axis = 1, skipna = True)\n",
        "trainRealdlon['flon']= trainRealdlon.sum(axis = 1, skipna = True)\n",
        "trainRealdlat['flat']= trainRealdlat.sum(axis = 1, skipna = True)\n",
        "\n",
        "trainPredlon['lon']= trainPreddlon['flon']\n",
        "trainPredlat['lat']= trainPreddlat['flat']\n",
        "trainReallon['lon']= trainRealdlon['flon']\n",
        "trainReallat['lat']= trainRealdlat['flat']\n",
        "dfpredictlon['lon']=dfpredictdlon['flon']\n",
        "dfpredictlat['lat']=dfpredictdlat['flat']\n",
        "dftestlon['lon']=dftestdlon['flon']\n",
        "dftestlat['lat']=dftestdlat['flat']\n",
        "\n",
        "print(\"Test northing MSE: \", mean_squared_error(dftestlat, dfpredictlat))\n",
        "\n",
        "print(\"Test northing R2: \", r2_score(dftestlon, dfpredictlon))\n",
        "\n",
        "print(\"Test easting MSE: \", mean_squared_error(dftestlon, dfpredictlon))\n",
        "\n",
        "print(\"Test easting R2: \", r2_score(dftestlat, dfpredictlat))\n",
        "\n",
        "print(\"Test northing MAE: \", mean_absolute_error(dftestlat, dfpredictlat))\n",
        "\n",
        "print(\"Test easting MAE: \", mean_absolute_error(dftestlon, dfpredictlon))\n",
        "\n",
        "df_predtrainresults= pd.DataFrame([])\n",
        "df_trainresults = pd.DataFrame([])\n",
        "df1= pd.DataFrame([])\n",
        "\n",
        "df_predtrainresults[\"long_latPREDICT\"] = list(zip(trainPredlon['lon'], trainPredlat['lat']))\n",
        "df_trainresults[\"long_latRESULT\"] = list(zip(trainReallon['lon'], trainReallat['lat']))\n",
        "\n",
        "df1['prediction']=df_predtrainresults[\"long_latPREDICT\"]\n",
        "df1['reality']=df_trainresults[\"long_latRESULT\"]\n",
        "\n",
        "def distance(df1):\n",
        "  return math.dist(df1['prediction'],df1['reality'])\n",
        "\n",
        "df1[\"distance(m)\"] = df1.apply(distance, axis =1)\n",
        "df1[\"distance(m)\"].mean()\n",
        "#18886.096412101044 meso sfalma sto train set 18,88609 km  me ola ta matzounia kai 5 epochs\n",
        "\n",
        "df_predresults = pd.DataFrame([])\n",
        "df_testresults = pd.DataFrame([])\n",
        "df= pd.DataFrame([])\n",
        "df_predresults[\"long_latPREDICT\"] = list(zip(dfpredictlon['lon'], dfpredictlat['lat']))\n",
        "df_testresults[\"long_latRESULT\"] = list(zip(dftestlon['lon'], dftestlat['lat']))\n",
        "#!pip install haversine\n",
        "#from haversine import haversine, Unit\n",
        "\n",
        "#arr_pred = df_predresults.to_numpy()\n",
        "#arr_test = df_testresults.to_numpy()\n",
        "\n",
        "df['prediction']=df_predresults[\"long_latPREDICT\"]\n",
        "df['reality']=df_testresults[\"long_latRESULT\"]\n",
        "\n",
        "\n",
        "def distance(df):\n",
        "  return math.dist(df['prediction'],df['reality'])\n",
        "\n",
        "df[\"distance(m)\"] = df.apply(distance, axis =1)\n",
        "df[\"distance(m)\"].mean()\n",
        "\n",
        "\n",
        "testxdf = scaler5.inverse_transform(df_testx)\n",
        "\n",
        "\n",
        "dfftestx = pd.DataFrame(testxdf,columns=columns)\n",
        "\n",
        "df[\"dt\"]=dfftestx['dt(t)']\n",
        "df\n",
        "max(df['distance(m)'])\n",
        "\n",
        "\n",
        "index1=0\n",
        "index2=0\n",
        "index3=0\n",
        "index4=0\n",
        "index5=0\n",
        "index6=0\n",
        "index7=0\n",
        "index8=0\n",
        "index9=0\n",
        "index10=0\n",
        "index11=0\n",
        "index12=0\n",
        "index13=0\n",
        "index14=0\n",
        "index15=0\n",
        "index16=0\n",
        "index17=0\n",
        "index18=0\n",
        "index19=0\n",
        "index20=0\n",
        "index21=0\n",
        "index22=0\n",
        "index23=0\n",
        "index24=0\n",
        "index25=0\n",
        "index26=0\n",
        "index27=0\n",
        "index28=0\n",
        "index29=0\n",
        "dist1740=0\n",
        "dist1680=0\n",
        "dist1620=0\n",
        "dist1560=0\n",
        "dist1500=0\n",
        "dist1440=0\n",
        "dist1380=0\n",
        "dist1320=0\n",
        "dist1260=0\n",
        "dist1200=0\n",
        "dist1140=0\n",
        "dist1080=0\n",
        "dist1020=0\n",
        "dist960=0\n",
        "dist900=0\n",
        "dist840=0\n",
        "dist780=0\n",
        "dist720=0\n",
        "dist660=0\n",
        "dist600=0\n",
        "dist540=0\n",
        "dist480=0\n",
        "dist420=0\n",
        "dist360=0\n",
        "dist300=0\n",
        "dist240=0\n",
        "dist180=0\n",
        "dist120=0\n",
        "dist60=0\n",
        "for index, row in df.iterrows(): \n",
        "  window= row[3]\n",
        "  if window>=1740 and window<=1800:\n",
        "          dist1740=dist1740+row[2] \n",
        "          index1=index1+1\n",
        "  if window>=1680 and window<1740:\n",
        "          dist1680=dist1680+row[2] \n",
        "          index2=index2+1\n",
        "  if window>=1620 and window<1680:\n",
        "          dist1620=dist1620+row[2] \n",
        "          index3=index3+1\n",
        "  if window>=1560 and window<1620:\n",
        "          dist1560=dist1560+row[2] \n",
        "          index4=index4+1\n",
        "  if window>=1500 and window<1560:\n",
        "          dist1500=dist1500+row[2] \n",
        "          index5=index5+1\n",
        "  if window>=1440 and window<1500:\n",
        "          dist1440=dist1440+row[2] \n",
        "          index6=index6+1\n",
        "  if window>=1380 and window<1440:\n",
        "          dist1380=dist1380+row[2] \n",
        "          index7=index7+1\n",
        "  if window>=1320 and window<1380:\n",
        "          dist1320=dist1320+row[2] \n",
        "          index8=index8+1\n",
        "  if window>=1260 and window<1320:\n",
        "          dist1260=dist1260+row[2] \n",
        "          index9=index9+1    \n",
        "  if window>=1200 and window<1260:\n",
        "          dist1200=dist1200+row[2] \n",
        "          index10=index10+1\n",
        "  if window>=1140 and window<1200:\n",
        "          dist1140=dist1140+row[2] \n",
        "          index11=index11+1\n",
        "  if window>=1080 and window<1140:\n",
        "          dist1080=dist1080+row[2] \n",
        "          index12=index12+1\n",
        "  if window>=1020 and window<1080:\n",
        "          dist1020=dist1020+row[2] \n",
        "          index13=index13+1\n",
        "  if window>=960 and window<1020:\n",
        "          dist960=dist960+row[2] \n",
        "          index14=index14+1\n",
        "  if window>=900 and window<960:\n",
        "          dist900=dist900+row[2] \n",
        "          index15=index15+1\n",
        "  if window>=840 and window<900:\n",
        "          dist840=dist840+row[2] \n",
        "          index16=index16+1\n",
        "  if window>=780 and window<840:\n",
        "          dist780=dist780+row[2] \n",
        "          index17=index17+1\n",
        "  if window>=720 and window<780:\n",
        "          dist720=dist720+row[2] \n",
        "          index18=index18+1\n",
        "  if window>=660 and window<720:\n",
        "          dist660=dist660+row[2] \n",
        "          index19=index19+1\n",
        "  if window>=600 and window<660:\n",
        "          dist600=dist600+row[2] \n",
        "          index20=index20+1\n",
        "  if window>=540 and window<600:\n",
        "          dist540=dist540+row[2] \n",
        "          index21=index21+1\n",
        "  if window>=480 and window<540:\n",
        "          dist480=dist480+row[2] \n",
        "          index22=index22+1\n",
        "  if window>=420 and window<480:\n",
        "          dist420=dist420+row[2] \n",
        "          index23=index23+1\n",
        "  if window>=360 and window<420:\n",
        "          dist360=dist360+row[2] \n",
        "          index24=index24+1\n",
        "  if window>=300 and window<360:\n",
        "          dist300=dist300+row[2] \n",
        "          index25=index25+1\n",
        "  if window>=240 and window<300:\n",
        "          dist240=dist240+row[2] \n",
        "          index26=index26+1\n",
        "  if window>=180 and window<240:\n",
        "          dist180=dist180+row[2] \n",
        "          index27=index27+1\n",
        "  if window>=120 and window<180:\n",
        "          dist120=dist120+row[2] \n",
        "          index28=index28+1\n",
        "  if window>=0 and window<120:\n",
        "          dist60=dist60+row[2] \n",
        "          index29=index29+1\n",
        "        \n",
        "#dist1740,dist1680,dist1620,dist1560,dist1500,dist1440,dist1380,dist1320,dist1200,dist1200,dist1140,\n",
        "#dist1080,dist1020,dist960,dist900,dist840,dist780,dist720,dist660,dist600,dist540,dist480,dist420,\n",
        "#dist360,dist300,dist240,dist180,dist120,dist60\n",
        "\n",
        "print( '[0,2)&' ,(dist60/index29)/1000, index29)\n",
        "print( '[2,3)&' ,(dist120/index28)/1000,index28)\n",
        "print( '[3,4)&' ,(dist180/index27)/1000,index27)  \n",
        "print( '[4,5)&' ,(dist240/index26)/1000,index26)  \n",
        "print( '[5,6)&' ,(dist300/index25) /1000,index25) \n",
        "print( '[6,7)&' ,(dist360/index24) /1000,index24) \n",
        "print( '[7,8)&' ,(dist420/index23)/1000,index23)\n",
        "print( '[8,9)&' ,(dist480/index22) /1000,index22) \n",
        "print( '[9,10)&' ,(dist540/index21) /1000,index21) \n",
        "print( '[10,11)&' ,(dist600/index20)/1000,index20) \n",
        "print( '[11,12)&' ,(dist660/index19) /1000,index19) \n",
        "print( '[12,13)&' ,(dist720/index18)/1000,index18)\n",
        "print( '[13,14)&' ,(dist780 /index17) /1000,index17) \n",
        "print( '[14,15)&' ,(dist840/index16) /1000,index16) \n",
        "print( '[15,16)&' ,(dist900/index15)/1000,index15) \n",
        "print( '[16,17)&' ,(dist960/index14) /1000,index14) \n",
        "print( '[17,18)&' ,(dist1020/index13)/1000,index13)\n",
        "print( '[18,19)&' ,(dist1080/index12) /1000,index12) \n",
        "print( '[19,20)&' ,(dist1140/index11) /1000,index11) \n",
        "print( '[20,21)&' ,(dist1200/index10)/1000,index10) \n",
        "print( '[21,22)&' ,(dist1260/index9)  /1000,index9)\n",
        "print( '[22,23)&' ,(dist1320 /index8)/1000,index8)\n",
        "print( '[23,24)&' ,(dist1380/index7) /1000,index7) \n",
        "print( '[24,25)&' ,(dist1440/index6)/1000,index6)  \n",
        "print( '[25,26)&' ,(dist1500/index5)/1000,index5) \n",
        "print( '[26,27)&' ,(dist1560/index4)/1000,index4)  \n",
        "print( '[27,28)&' ,(dist1620/index3)/1000,index3)\n",
        "print( '[28,29)&' ,(dist1680/index2)/1000,index2)  \n",
        "print( '[29,30)&' ,(dist1740/index1)/1000,index1)  "
      ],
      "metadata": {
        "id": "hWGfvBjM17HB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c73122b-f7c6-4e89-aafd-abaaa8ea99d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "811/811 [==============================] - 1s 1ms/step\n",
            "675/675 [==============================] - 1s 1ms/step\n",
            "Test northing MSE:  468899.18983213103\n",
            "Test northing R2:  0.9996416340163309\n",
            "Test easting MSE:  855112.1083481195\n",
            "Test easting R2:  0.9999048497946893\n",
            "Test northing MAE:  428.32749050108947\n",
            "Test easting MAE:  589.3547727957032\n",
            "[0,2)& 0.48995698185828507 159\n",
            "[2,3)& 0.7643220137871447 15024\n",
            "[3,4)& 1.1446933735386653 5535\n",
            "[4,5)& 0.6680958870221847 228\n",
            "[5,6)& 1.2686106052514476 96\n",
            "[6,7)& 1.3260672308544186 48\n",
            "[7,8)& 1.9000152592779636 42\n",
            "[8,9)& 1.2252742708609965 59\n",
            "[9,10)& 1.4673013106759256 45\n",
            "[10,11)& 1.5206092284980062 42\n",
            "[11,12)& 1.3143624914764187 39\n",
            "[12,13)& 1.302299611740889 35\n",
            "[13,14)& 1.18605793192332 27\n",
            "[14,15)& 1.42419456479779 41\n",
            "[15,16)& 1.5693550361802517 18\n",
            "[16,17)& 2.4213437161465006 24\n",
            "[17,18)& 2.5370563835107167 16\n",
            "[18,19)& 1.0976679183973805 9\n",
            "[19,20)& 1.124847508942318 11\n",
            "[20,21)& 2.614140510994412 9\n",
            "[21,22)& 3.4768433740605036 12\n",
            "[22,23)& 4.315300015296034 11\n",
            "[23,24)& 1.929164039316909 14\n",
            "[24,25)& 1.6628251439067518 8\n",
            "[25,26)& 1.404050081059772 5\n",
            "[26,27)& 1.2450848192453783 9\n",
            "[27,28)& 2.151881966489268 6\n",
            "[28,29)& 3.6712928304490218 7\n",
            "[29,30)& 3.4079392896331924 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Predicting and plotting the result\n",
        "trainPredict = model.predict(df_trx, batch_size=batch_size)\n",
        "testPredict = model.predict(df_testx, batch_size=batch_size)\n",
        "\n",
        "# invert predictions\n",
        "#(25925, 1) (21585, 1)\n",
        "trainPredict = np.reshape(trainPredict, (-1, 2))\n",
        "ytr2d = np.reshape(df_try, (-1, 2))\n",
        "\n",
        "testPredict = np.reshape(testPredict, (-1, 2))\n",
        "yte2d = np.reshape(df_testy, (-1, 2))\n",
        "trainPredict\n",
        "\n",
        "\n",
        "trainPredict = scaler2.inverse_transform(trainPredict)\n",
        "trainY = scaler2.inverse_transform(ytr2d)\n",
        "\n",
        "testPredict = scaler6.inverse_transform(testPredict)\n",
        "testY = scaler6.inverse_transform(yte2d)\n",
        "\n",
        "dfpredict = pd.DataFrame(testPredict,columns=['dlon','dlat'])\n",
        "dftest= pd.DataFrame(testY,columns=['dlon','dlat'])\n",
        "trainPred= pd.DataFrame(trainPredict,columns=['dlon','dlat'])\n",
        "trainReal= pd.DataFrame(trainY,columns=['dlon','dlat'])\n",
        "\n",
        "\n",
        "\n",
        "dfpredictdlon= pd.DataFrame([])\n",
        "dftestdlon= pd.DataFrame([])\n",
        "trainPreddlon =pd.DataFrame([])\n",
        "trainRealdlon = pd.DataFrame([])\n",
        "dfpredictdlat= pd.DataFrame([])\n",
        "dftestdlat= pd.DataFrame([])\n",
        "trainPreddlat = pd.DataFrame([])\n",
        "trainRealdlat =pd.DataFrame([])\n",
        "\n",
        "dfpredictdlon['dlon']=dfpredict['dlon']\n",
        "dftestdlon['dlon']= dftest['dlon']\n",
        "trainPreddlon['dlon'] = trainPred['dlon']\n",
        "trainRealdlon['dlon'] = trainReal['dlon']\n",
        "dfpredictdlat['dlat']= dfpredict['dlat']\n",
        "dftestdlat['dlat']= dftest['dlat']\n",
        "trainPreddlat['dlat'] = trainPred['dlat']\n",
        "trainRealdlat['dlat'] = trainReal['dlat']\n",
        "\n",
        "\n",
        "dfpredictdlon['lon']=dftestzlon[\"lon(t-1)\"].values\n",
        "dfpredictdlat['lat'] =dftestzlat[\"lat(t-1)\"].values\n",
        "dftestdlon['lon']=dftestzlon[\"lon(t-1)\"].values\n",
        "dftestdlat['lat'] =dftestzlat[\"lat(t-1)\"].values\n",
        "\n",
        "trainPreddlon['lon'] =dftrainzlon[\"lon(t-1)\"].values\n",
        "trainRealdlon['lon'] =dftrainzlon[\"lon(t-1)\"].values\n",
        "trainPreddlat['lat'] =dftrainzlat[\"lat(t-1)\"].values\n",
        "trainRealdlat['lat'] =dftrainzlat[\"lat(t-1)\"].values\n",
        "\n",
        "\n",
        "\n",
        "#df.sum(axis = 1, skipna = True)\n",
        "\n",
        "trainPredlon= pd.DataFrame([])\n",
        "trainPredlat= pd.DataFrame([])\n",
        "trainReallon= pd.DataFrame([])\n",
        "trainReallat= pd.DataFrame([])\n",
        "dfpredictlon= pd.DataFrame([])\n",
        "dfpredictlat= pd.DataFrame([])\n",
        "dftestlon= pd.DataFrame([])\n",
        "dftestlat= pd.DataFrame([])\n",
        "dfpredictdlon['flon']=dfpredictdlon.sum(axis = 1, skipna = True)\n",
        "dfpredictdlat['flat']= dfpredictdlat.sum(axis = 1, skipna = True)\n",
        "dftestdlon['flon']= dftestdlon.sum(axis = 1, skipna = True)\n",
        "dftestdlat['flat']= dftestdlat.sum(axis = 1, skipna = True)\n",
        "\n",
        "trainPreddlon['flon']= trainPreddlon.sum(axis = 1, skipna = True)\n",
        "trainPreddlat['flat']= trainPreddlat.sum(axis = 1, skipna = True)\n",
        "trainRealdlon['flon']= trainRealdlon.sum(axis = 1, skipna = True)\n",
        "trainRealdlat['flat']= trainRealdlat.sum(axis = 1, skipna = True)\n",
        "\n",
        "trainPredlon['lon']= trainPreddlon['flon']\n",
        "trainPredlat['lat']= trainPreddlat['flat']\n",
        "trainReallon['lon']= trainRealdlon['flon']\n",
        "trainReallat['lat']= trainRealdlat['flat']\n",
        "dfpredictlon['lon']=dfpredictdlon['flon']\n",
        "dfpredictlat['lat']=dfpredictdlat['flat']\n",
        "dftestlon['lon']=dftestdlon['flon']\n",
        "dftestlat['lat']=dftestdlat['flat']\n",
        "\n",
        "print(\"Test easting MSE: \", mean_squared_error(dftestlon, dfpredictlon))\n",
        "\n",
        "print(\"Test easting R2: \", r2_score(dftestlon, dfpredictlon))\n",
        "\n",
        "print(\"Test northing MSE: \", mean_squared_error(dftestlat, dfpredictlat))\n",
        "\n",
        "print(\"Test northing R2: \", r2_score(dftestlat, dfpredictlat))\n",
        "print(\"Test easting MSE: \", mean_absolute_error(dftestlon, dfpredictlon))\n",
        "print(\"Test northing MSE: \", mean_absolute_error(dftestlat, dfpredictlat))\n",
        "\n",
        "df_predtrainresults= pd.DataFrame([])\n",
        "df_trainresults = pd.DataFrame([])\n",
        "df1= pd.DataFrame([])\n",
        "\n",
        "df_predtrainresults[\"long_latPREDICT\"] = list(zip(trainPredlon['lon'], trainPredlat['lat']))\n",
        "df_trainresults[\"long_latRESULT\"] = list(zip(trainReallon['lon'], trainReallat['lat']))\n",
        "\n",
        "df1['prediction']=df_predtrainresults[\"long_latPREDICT\"]\n",
        "df1['reality']=df_trainresults[\"long_latRESULT\"]\n",
        "\n",
        "def distance(df1):\n",
        "  return math.dist(df1['prediction'],df1['reality'])\n",
        "\n",
        "df1[\"distance(m)\"] = df1.apply(distance, axis =1)\n",
        "df1[\"distance(m)\"].mean()\n",
        "#18886.096412101044 meso sfalma sto train set 18,88609 km  me ola ta matzounia kai 5 epochs\n",
        "\n",
        "df_predresults = pd.DataFrame([])\n",
        "df_testresults = pd.DataFrame([])\n",
        "df= pd.DataFrame([])\n",
        "df_predresults[\"long_latPREDICT\"] = list(zip(dfpredictlon['lon'], dfpredictlat['lat']))\n",
        "df_testresults[\"long_latRESULT\"] = list(zip(dftestlon['lon'], dftestlat['lat']))\n",
        "#!pip install haversine\n",
        "#from haversine import haversine, Unit\n",
        "\n",
        "#arr_pred = df_predresults.to_numpy()\n",
        "#arr_test = df_testresults.to_numpy()\n",
        "\n",
        "df['prediction']=df_predresults[\"long_latPREDICT\"]\n",
        "df['reality']=df_testresults[\"long_latRESULT\"]\n",
        "\n",
        "\n",
        "def distance(df):\n",
        "  return math.dist(df['prediction'],df['reality'])\n",
        "\n",
        "df[\"distance(m)\"] = df.apply(distance, axis =1)\n",
        "df[\"distance(m)\"].mean()\n",
        "\n",
        "\n",
        "testxdf = scaler5.inverse_transform(df_testx)\n",
        "\n",
        "\n",
        "dfftestx = pd.DataFrame(testxdf,columns=columns)\n",
        "\n",
        "df[\"dt\"]=dfftestx['dt(t)']\n",
        "df\n",
        "max(df['distance(m)'])\n",
        "\n",
        "\n",
        "index1=0\n",
        "index2=0\n",
        "index3=0\n",
        "index4=0\n",
        "index5=0\n",
        "index6=0\n",
        "index7=0\n",
        "index8=0\n",
        "index9=0\n",
        "index10=0\n",
        "index11=0\n",
        "index12=0\n",
        "index13=0\n",
        "index14=0\n",
        "index15=0\n",
        "index16=0\n",
        "index17=0\n",
        "index18=0\n",
        "index19=0\n",
        "index20=0\n",
        "index21=0\n",
        "index22=0\n",
        "index23=0\n",
        "index24=0\n",
        "index25=0\n",
        "index26=0\n",
        "index27=0\n",
        "index28=0\n",
        "index29=0\n",
        "dist1740=0\n",
        "dist1680=0\n",
        "dist1620=0\n",
        "dist1560=0\n",
        "dist1500=0\n",
        "dist1440=0\n",
        "dist1380=0\n",
        "dist1320=0\n",
        "dist1260=0\n",
        "dist1200=0\n",
        "dist1140=0\n",
        "dist1080=0\n",
        "dist1020=0\n",
        "dist960=0\n",
        "dist900=0\n",
        "dist840=0\n",
        "dist780=0\n",
        "dist720=0\n",
        "dist660=0\n",
        "dist600=0\n",
        "dist540=0\n",
        "dist480=0\n",
        "dist420=0\n",
        "dist360=0\n",
        "dist300=0\n",
        "dist240=0\n",
        "dist180=0\n",
        "dist120=0\n",
        "dist60=0\n",
        "for index, row in df.iterrows(): \n",
        "  window= row[3]\n",
        "  if window>=1740 and window<=1800:\n",
        "          dist1740=dist1740+row[2] \n",
        "          index1=index1+1\n",
        "  if window>=1680 and window<1740:\n",
        "          dist1680=dist1680+row[2] \n",
        "          index2=index2+1\n",
        "  if window>=1620 and window<1680:\n",
        "          dist1620=dist1620+row[2] \n",
        "          index3=index3+1\n",
        "  if window>=1560 and window<1620:\n",
        "          dist1560=dist1560+row[2] \n",
        "          index4=index4+1\n",
        "  if window>=1500 and window<1560:\n",
        "          dist1500=dist1500+row[2] \n",
        "          index5=index5+1\n",
        "  if window>=1440 and window<1500:\n",
        "          dist1440=dist1440+row[2] \n",
        "          index6=index6+1\n",
        "  if window>=1380 and window<1440:\n",
        "          dist1380=dist1380+row[2] \n",
        "          index7=index7+1\n",
        "  if window>=1320 and window<1380:\n",
        "          dist1320=dist1320+row[2] \n",
        "          index8=index8+1\n",
        "  if window>=1260 and window<1320:\n",
        "          dist1260=dist1260+row[2] \n",
        "          index9=index9+1    \n",
        "  if window>=1200 and window<1260:\n",
        "          dist1200=dist1200+row[2] \n",
        "          index10=index10+1\n",
        "  if window>=1140 and window<1200:\n",
        "          dist1140=dist1140+row[2] \n",
        "          index11=index11+1\n",
        "  if window>=1080 and window<1140:\n",
        "          dist1080=dist1080+row[2] \n",
        "          index12=index12+1\n",
        "  if window>=1020 and window<1080:\n",
        "          dist1020=dist1020+row[2] \n",
        "          index13=index13+1\n",
        "  if window>=960 and window<1020:\n",
        "          dist960=dist960+row[2] \n",
        "          index14=index14+1\n",
        "  if window>=900 and window<960:\n",
        "          dist900=dist900+row[2] \n",
        "          index15=index15+1\n",
        "  if window>=840 and window<900:\n",
        "          dist840=dist840+row[2] \n",
        "          index16=index16+1\n",
        "  if window>=780 and window<840:\n",
        "          dist780=dist780+row[2] \n",
        "          index17=index17+1\n",
        "  if window>=720 and window<780:\n",
        "          dist720=dist720+row[2] \n",
        "          index18=index18+1\n",
        "  if window>=660 and window<720:\n",
        "          dist660=dist660+row[2] \n",
        "          index19=index19+1\n",
        "  if window>=600 and window<660:\n",
        "          dist600=dist600+row[2] \n",
        "          index20=index20+1\n",
        "  if window>=540 and window<600:\n",
        "          dist540=dist540+row[2] \n",
        "          index21=index21+1\n",
        "  if window>=480 and window<540:\n",
        "          dist480=dist480+row[2] \n",
        "          index22=index22+1\n",
        "  if window>=420 and window<480:\n",
        "          dist420=dist420+row[2] \n",
        "          index23=index23+1\n",
        "  if window>=360 and window<420:\n",
        "          dist360=dist360+row[2] \n",
        "          index24=index24+1\n",
        "  if window>=300 and window<360:\n",
        "          dist300=dist300+row[2] \n",
        "          index25=index25+1\n",
        "  if window>=240 and window<300:\n",
        "          dist240=dist240+row[2] \n",
        "          index26=index26+1\n",
        "  if window>=180 and window<240:\n",
        "          dist180=dist180+row[2] \n",
        "          index27=index27+1\n",
        "  if window>=120 and window<180:\n",
        "          dist120=dist120+row[2] \n",
        "          index28=index28+1\n",
        "  if window>=0 and window<120:\n",
        "          dist60=dist60+row[2] \n",
        "          index29=index29+1\n",
        "        \n",
        "#dist1740,dist1680,dist1620,dist1560,dist1500,dist1440,dist1380,dist1320,dist1200,dist1200,dist1140,\n",
        "#dist1080,dist1020,dist960,dist900,dist840,dist780,dist720,dist660,dist600,dist540,dist480,dist420,\n",
        "#dist360,dist300,dist240,dist180,dist120,dist60\n",
        "\n",
        "\n",
        "print( '[0,2)&' ,(dist60/index29)/1000, index29)\n",
        "print( '[2,3)&' ,(dist120/index28)/1000,index28)\n",
        "print( '[3,4)&' ,(dist180/index27)/1000,index27)  \n",
        "print( '[4,5)&' ,(dist240/index26)/1000,index26)  \n",
        "print( '[5,6)&' ,(dist300/index25) /1000,index25) \n",
        "print( '[6,7)&' ,(dist360/index24) /1000,index24) \n",
        "print( '[7,8)&' ,(dist420/index23)/1000,index23)\n",
        "print( '[8,9)&' ,(dist480/index22) /1000,index22) \n",
        "print( '[9,10)&' ,(dist540/index21) /1000,index21) \n",
        "print( '[10,11)&' ,(dist600/index20)/1000,index20) \n",
        "print( '[11,12)&' ,(dist660/index19) /1000,index19) \n",
        "print( '[12,13)&' ,(dist720/index18)/1000,index18)\n",
        "print( '[13,14)&' ,(dist780 /index17) /1000,index17) \n",
        "print( '[14,15)&' ,(dist840/index16) /1000,index16) \n",
        "print( '[15,16)&' ,(dist900/index15)/1000,index15) \n",
        "print( '[16,17)&' ,(dist960/index14) /1000,index14) \n",
        "print( '[17,18)&' ,(dist1020/index13)/1000,index13)\n",
        "print( '[18,19)&' ,(dist1080/index12) /1000,index12) \n",
        "print( '[19,20)&' ,(dist1140/index11) /1000,index11) \n",
        "print( '[20,21)&' ,(dist1200/index10)/1000,index10) \n",
        "print( '[21,22)&' ,(dist1260/index9)  /1000,index9)\n",
        "print( '[22,23)&' ,(dist1320 /index8)/1000,index8)\n",
        "print( '[23,24)&' ,(dist1380/index7) /1000,index7) \n",
        "print( '[24,25)&' ,(dist1440/index6)/1000,index6)  \n",
        "print( '[25,26)&' ,(dist1500/index5)/1000,index5) \n",
        "print( '[26,27)&' ,(dist1560/index4)/1000,index4)  \n",
        "print( '[27,28)&' ,(dist1620/index3)/1000,index3)\n",
        "print( '[28,29)&' ,(dist1680/index2)/1000,index2)  \n",
        "print( '[29,30)&' ,(dist1740/index1)/1000,index1)  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwb4EkjoRYf2",
        "outputId": "4b433a29-5322-47d2-deb0-f2de896bce0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "811/811 [==============================] - 2s 3ms/step\n",
            "675/675 [==============================] - 2s 3ms/step\n",
            "Test easting MSE:  1060.096619373108\n",
            "Test easting R2:  0.9992991402253263\n",
            "Test northing MSE:  668.4945416566013\n",
            "Test northing R2:  0.999841438079627\n",
            "distance km under 2 minutes 0.8892305118990407 159\n",
            "distance km under 3 minutes 1.1982653343434746 15024\n",
            "distance km under 4 minutes 1.7552382668024975 5535\n",
            "distance km under 5 minutes 1.594483856349024 228\n",
            "distance km under 6 minutes 2.3637850271942136 96\n",
            "distance km under 7 minutes 2.759145039399909 48\n",
            "distance km under 8 minutes 3.1765236716659353 42\n",
            "distance km under 9 minutes 2.1281231980439745 59\n",
            "distance km under 10 minutes 2.5263352612130587 45\n",
            "distance km under 11 minutes 2.1236552560191115 42\n",
            "distance km under 12 minutes 1.49325395575635 39\n",
            "distance km under 13 minutes 2.427047074088517 35\n",
            "distance km under 14 minutes 1.5423890563890779 27\n",
            "distance km under 15 minutes 2.3074973388436906 41\n",
            "distance km under 16 minutes 2.607774204540595 18\n",
            "distance km under 17 minutes 2.840431556135471 24\n",
            "distance km under 18 minutes 3.6846705575388303 16\n",
            "distance km under 19 minutes 1.2806193743621634 9\n",
            "distance km under 20 minutes 3.1088212428246504 11\n",
            "distance km under 21 minutes 3.7671055279668226 9\n",
            "distance km under 22 minutes 4.934184402064986 12\n",
            "distance km under 23 minutes 4.621171760735499 11\n",
            "distance km under 24 minutes 2.894644215244566 14\n",
            "distance km under 25 minutes 3.174661661584924 8\n",
            "distance km under 26 minutes 3.633879131082881 5\n",
            "distance km under 27 minutes 1.1655045058173443 9\n",
            "distance km under 28 minutes 1.5451697097010693 6\n",
            "distance km under 29 minutes 7.1465221396136425 7\n",
            "distance km under 30 minutes 7.222526829342923 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle \n",
        "with open('32sigmoid16sigmoid8sigmoid4sigmoid2sigmoiddlondlatmodel.pickle','wb') as file:\n",
        "  pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "hAI1efes72Ol"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}